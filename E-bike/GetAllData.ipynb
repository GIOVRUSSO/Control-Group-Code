{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  2019-11-18-21-28 . Avg HR:  111\n",
      "Time:  2019-11-18-21-28 . Avg EDA:  0.15216271512500024\n",
      "Time:  2019-11-18-21-28 . Avg HP:  0.0 . Ave ThrOut:  1.0 \n",
      "\n",
      "U =  0.0\n",
      "Time:  2019-11-18-21-29 . Avg HR:  71\n",
      "Time:  2019-11-18-21-29 . Avg EDA:  0.1499145032083333\n",
      "Bike Data at 2019-11-18-21-30 does not exist\n",
      "U =  0.0\n",
      "Time:  2019-11-18-21-30 . Avg HR:  62\n",
      "Time:  2019-11-18-21-31 . Avg EDA:  0.18190743753749983\n",
      "Time:  2019-11-18-21-31 . Avg HP:  140.77586206896552 . Ave ThrOut:  2.3663275858451582 \n",
      "\n",
      "Error finding previous MPC output data\n",
      "U =  0.0\n",
      "Time:  2019-11-18-21-31 . Avg HR:  46\n",
      "Time:  2019-11-18-21-32 . Avg EDA:  0.16211678337499988\n",
      "Time:  2019-11-18-21-32 . Avg HP:  175.74137931034483 . Ave ThrOut:  2.4978965603072067 \n",
      "\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-0f4e0085690b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 698\u001b[0;31m         \u001b[0mschedule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_pending\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/schedule/__init__.py\u001b[0m in \u001b[0;36mrun_pending\u001b[0;34m()\u001b[0m\n\u001b[1;32m    561\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mdefault\u001b[0m \u001b[0mscheduler\u001b[0m \u001b[0minstance\u001b[0m \u001b[0;34m<\u001b[0m\u001b[0mdefault_scheduler\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m     \"\"\"\n\u001b[0;32m--> 563\u001b[0;31m     \u001b[0mdefault_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_pending\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/schedule/__init__.py\u001b[0m in \u001b[0;36mrun_pending\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0mrunnable_jobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mjob\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjobs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_run\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mjob\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrunnable_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelay_seconds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/schedule/__init__.py\u001b[0m in \u001b[0;36m_run_job\u001b[0;34m(self, job)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelJob\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mCancelJob\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcancel_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/schedule/__init__.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    464\u001b[0m         \"\"\"\n\u001b[1;32m    465\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Running job %s'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_run\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_schedule_next_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-0f4e0085690b>\u001b[0m in \u001b[0;36mModelAndControl\u001b[0;34m(u, t)\u001b[0m\n\u001b[1;32m    458\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcurrCycleReadings\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m             \u001b[0;31m# Recorded Data Constraints\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m             \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEquation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1h\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mx1h\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0ma12\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx2h\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ma13\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx3h\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb1\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0muh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    461\u001b[0m             \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEquation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2h\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mx2h\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0ma21\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx1h\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ma23\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx3h\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0muh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m             \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEquation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx3h\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mx3h\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0ma31\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx1h\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ma32\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx2h\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb3\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0muh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    866\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   4373\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4374\u001b[0m             return self._engine.get_value(s, k,\n\u001b[0;32m-> 4375\u001b[0;31m                                           tz=getattr(series.dtype, 'tz', None))\n\u001b[0m\u001b[1;32m   4376\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4377\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mholds_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_boolean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 3"
     ]
    }
   ],
   "source": [
    "#!/bin/python\n",
    "\n",
    "import dropbox\n",
    "import datetime\n",
    "import schedule\n",
    "import numpy\n",
    "import numpy\n",
    "import string\n",
    "import requests \n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "from threading import Timer\n",
    "import time\n",
    "import sys\n",
    "\n",
    "import csv\n",
    "\n",
    "import math\n",
    "import random\n",
    "import matplotlib\n",
    "# import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "import os\n",
    "\n",
    "import matplotlib.dates as mdate\n",
    "\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "\n",
    "import pytz\n",
    "import warnings\n",
    "from gekko import GEKKO\n",
    "\n",
    "class HR_Getting:\n",
    "    \n",
    "    def __init__():\n",
    "        dbx = dropbox.Dropbox('ZUWX93O8oqAAAAAAAAAAw8IuLkWSVq1JYofJm7O5Au6NbpQXhW_zhN-V6Sorptvb')\n",
    "        delta = datetime.timedelta(minutes=1)\n",
    "\n",
    "    def E4(x, y):\n",
    "        # Dropbox access token    \n",
    "        dbx = dropbox.Dropbox('ZUWX93O8oqAAAAAAAAAAw8IuLkWSVq1JYofJm7O5Au6NbpQXhW_zhN-V6Sorptvb')\n",
    "\n",
    "        # current time\n",
    "        timestamp = datetime.datetime.now()\n",
    "        # time gap\n",
    "        delta = datetime.timedelta(minutes = 1)\n",
    "        # time where the IBI file has been bulit\n",
    "        filetime = timestamp - delta\n",
    "\n",
    "#         Re-formatting: datetime->String\n",
    "        Str_filetime = filetime.strftime('%Y-%m-%d-%H-%M')\n",
    "#         Str_filetime = currTime\n",
    "\n",
    "        # For testing only \n",
    "        # Str_filetime = '2019-06-22-22-25'\n",
    "\n",
    "        # Set parameters for downloading the file \n",
    "        # Saving path\n",
    "        download_path = '/Users/tomstanton 1/Documents/College/Stage 5/ME Project/Data/E4data/BPM/'+Str_filetime+'.txt'\n",
    "        # File location in dropbox    \n",
    "        path = '/IBI/IBIData'+Str_filetime+'.txt'\n",
    "\n",
    "        # try download\n",
    "        try:\n",
    "            dbx.files_download_to_file(download_path,path,None)   \n",
    "        except:\n",
    "                print('IBI Data at '+Str_filetime+' does not exsit')\n",
    "                pass\n",
    "        else:\n",
    "#             print(\"Successful Downloading /Apps/E4Link\" + path + \" from Dropbox, overwriting \" + download_path + \"...\")\n",
    "\n",
    "            # A file downloaded, reformat the file\n",
    "            resval = numpy.loadtxt(download_path)\n",
    "\n",
    "            with open(download_path, 'r') as f:\n",
    "                sum = 0\n",
    "                count = 0\n",
    "                lines = f.readlines()  # read the content\n",
    "                for line in lines:\n",
    "                    for value in line.split():\n",
    "                        value = value.strip(string.whitespace)\n",
    "                        sum += float(value)\n",
    "                        count += 1\n",
    "                \n",
    "                f.close()\n",
    "                \n",
    "            aveIBI = sum / count\n",
    "            bpm = int(60 / aveIBI)\n",
    "            d5_bpm = int(bpm/5)\n",
    " \n",
    "            x.append(Str_filetime)\n",
    "            y.append(bpm)\n",
    "                \n",
    "#             fig = HR_Getting.draw(x, y)\n",
    "\n",
    "            with open('/Users/tomstanton 1/Documents/College/Stage 5/ME Project/Data/E4data/bpm_data.csv', 'a', newline='\\n') as f:\n",
    "                headers = ['time', 'bpm']\n",
    "                csv_write = csv.writer(f)\n",
    "                \n",
    "                \n",
    "                if not os.stat(\"/Users/tomstanton 1/Documents/College/Stage 5/ME Project/Data/E4data/bpm_data.csv\").st_size:    \n",
    "                    print('BPM Data file created')\n",
    "                    csv_write.writerow(headers) # file doesn't exist yet, write a header\n",
    "                \n",
    "                csv_write.writerow([Str_filetime, bpm])\n",
    "                f.close()\n",
    "                \n",
    "            print('Time: ', Str_filetime ,'. Avg HR: ', bpm,)\n",
    "\n",
    "    def bodyE4():\n",
    "        x = []\n",
    "        y = []\n",
    "        #plt.ion()\n",
    "        #plt.figure(1)\n",
    "        schedule.every(1).minutes.do(HR_Getting.E4, x, y)\n",
    "        while True:\n",
    "            schedule.run_pending()\n",
    "\n",
    "    def draw(x, y):\n",
    "        plt.clf()\n",
    "        plt.plot(x, y, '-r')\n",
    "        plt.tick_params(axis='x', rotation=90)\n",
    "        plt.title('bpm verus time')\n",
    "        plt.xlabel('time')\n",
    "        plt.ylabel('bpm')\n",
    "        plt.pause(0.01)  # pause a bit so that plots are updated\n",
    "        #plt.show\n",
    "        #if 'qt5' in matplotlib.get_backend():\n",
    "            #display.clear_output(wait=True)\n",
    "            #display.display(plt.gcf())\n",
    "# \n",
    "# \n",
    "# \n",
    "# \n",
    "# \n",
    "\n",
    "\n",
    "\n",
    "class SC_Getting:\n",
    "    \n",
    "    def __init__():\n",
    "        dbx = dropbox.Dropbox('ZUWX93O8oqAAAAAAAAAAw8IuLkWSVq1JYofJm7O5Au6NbpQXhW_zhN-V6Sorptvb')\n",
    "        delta = datetime.timedelta(minutes=1)\n",
    "\n",
    "    def E4(x, y):\n",
    "        # Dropbox access token    \n",
    "        dbx = dropbox.Dropbox('ZUWX93O8oqAAAAAAAAAAw8IuLkWSVq1JYofJm7O5Au6NbpQXhW_zhN-V6Sorptvb')\n",
    "\n",
    "        # current time\n",
    "        timestamp = datetime.datetime.now()\n",
    "        # time gap\n",
    "        delta = datetime.timedelta(minutes = 1)\n",
    "        # time where the IBI file has been bulit\n",
    "        filetime = timestamp - delta\n",
    "\n",
    "#         Re-formatting: datetime->String\n",
    "        Str_filetime = filetime.strftime('%Y-%m-%d-%H-%M')\n",
    "#         Str_filetime = currTime\n",
    "\n",
    "        # For testing only \n",
    "        # Str_filetime = '2019-06-22-22-25'\n",
    "\n",
    "        \n",
    "        # TODO insert\n",
    "        \n",
    "        # Set parameters for downloading the file \n",
    "        # Saving path\n",
    "        download_path = '/Users/tomstanton 1/Documents/College/Stage 5/ME Project/Data/E4data/EDA/'+Str_filetime+'.txt'\n",
    "        # File location in dropbox    \n",
    "        path = '/EDA/EDAData'+Str_filetime+'.txt'\n",
    "        \n",
    "        # to aviod network delay\n",
    "        \n",
    "        #time.sleep(10)\n",
    "        max = 10\n",
    "        start = time.time()\n",
    "        while True:\n",
    "            ### This will be updated every loop\n",
    "            remaining = max + start - time.time()\n",
    "#             print \"%s seconds remaining\" % int(remaining)\n",
    "\n",
    "            ### Countdown finished, ending loop\n",
    "            if remaining <= 0:\n",
    "                break\n",
    "        \n",
    "        # try download\n",
    "        try:\n",
    "            dbx.files_download_to_file(download_path,path,None)\n",
    "\n",
    "        except:\n",
    "                print('EDA Data at '+Str_filetime+' does not exsit')\n",
    "                pass\n",
    "        else:\n",
    "#             print(\"Successful Downloading /Apps/E4Link\" + path + \" from Dropbox, overwriting \" + download_path + \"...\")\n",
    "\n",
    "            # A file downloaded, reformat the file\n",
    "            resval = numpy.loadtxt(download_path)\n",
    "\n",
    "            with open(download_path, 'r') as f:\n",
    "                sum = 0\n",
    "                count = 0\n",
    "                lines = f.readlines()  # read the content\n",
    "                for line in lines:\n",
    "                    for value in line.split():\n",
    "                        value = value.strip(string.whitespace)\n",
    "                        sum += float(value)\n",
    "                        count += 1\n",
    "                \n",
    "                f.close()\n",
    "                \n",
    "            aveEDA = sum / count\n",
    "            d005_EDA = int(aveEDA/0.05)\n",
    " \n",
    "            x.append(Str_filetime)\n",
    "            y.append(aveEDA)\n",
    "                \n",
    "#             fig = SC_Getting.draw(x, y)\n",
    "\n",
    "            with open('/Users/tomstanton 1/Documents/College/Stage 5/ME Project/Data/E4data/eda_data.csv', 'a', newline='\\n') as f:\n",
    "                headers = ['time', 'aveEDA']\n",
    "                csv_write = csv.writer(f)\n",
    "                \n",
    "                if not os.stat(\"/Users/tomstanton 1/Documents/College/Stage 5/ME Project/Data/E4data/eda_data.csv\").st_size:         \n",
    "                    print('EDA Data file created')\n",
    "                    csv_write.writerow(headers) # file doesn't exist yet, write a header\n",
    "                \n",
    "                csv_write.writerow([Str_filetime,aveEDA])\n",
    "                f.close()\n",
    "                print('Time: ', Str_filetime ,'. Avg EDA: ', aveEDA)\n",
    "\n",
    "\n",
    "\n",
    "    def bodyE4():\n",
    "        x = []\n",
    "        y = []\n",
    "        #plt.ion()\n",
    "        #plt.figure(1)\n",
    "        schedule.every(1).minutes.do(SC_Getting.E4, x, y)\n",
    "        while True:\n",
    "            schedule.run_pending()\n",
    "\n",
    "    def draw(x, y):\n",
    "        plt.clf()\n",
    "        plt.plot(x, y, '-r')\n",
    "        plt.tick_params(axis='x', rotation=90)\n",
    "        plt.title('eda verus time')\n",
    "        plt.xlabel('time')\n",
    "        plt.ylabel('eda')\n",
    "        plt.pause(0.01)  # pause a bit so that plots are updated           \n",
    "# \n",
    "# \n",
    "# \n",
    "# \n",
    "\n",
    "\n",
    "\n",
    "class EBikeData_Getting:\n",
    "        \n",
    "    def EBike(x_t,y_hP):\n",
    "        # Dropbox access token    \n",
    "        dbx = dropbox.Dropbox('ZUWX93O8oqAAAAAAAAAAxEHAYxN4vo5YaNUpj9rUXX6A0PTm25VJRNpC-gVEn7QO')\n",
    "\n",
    "        # Set parameters for downloading the file \n",
    "        # Saving path\n",
    "        save_path = '/Users/tomstanton 1/Documents/College/Stage 5/ME Project/Data/Bikedata/Data.db'\n",
    "        # File location in dropbox    \n",
    "        path = '/EBike.db'\n",
    "\n",
    "         # current time\n",
    "        timestamp = datetime.datetime.now()\n",
    "        # time gap\n",
    "        delta = datetime.timedelta(minutes = 1)\n",
    "        # time where the IBI file has been bulit\n",
    "        filetime = timestamp - delta\n",
    "\n",
    "        # Re-formatting: datetime->String\n",
    "        timeframe = filetime.strftime('%Y-%m-%d %H:%M')\n",
    "        csv_filetime = filetime.strftime('%Y-%m-%d-%H-%M')\n",
    "#         timeframe = currTime\n",
    "#         csv_filetime = currTimeFrame\n",
    "        #res = dbx.files_list_folder(path,None)\n",
    "        #print (res)\n",
    "        # try download\n",
    "        try:\n",
    "            dbx.files_download_to_file(save_path,path,None)   \n",
    "        except:\n",
    "#                 print('')\n",
    "                pass\n",
    "        else:\n",
    "#             print(\"Successful Downloading database file from Dropbox, overwriting \" + save_path + \"...\")\n",
    "\n",
    "            # Save voltage of the motor and data which averaged\n",
    "            conn = sqlite3.connect(save_path)\n",
    "            cursor = conn.cursor()\n",
    "\n",
    "            #timeframe = '2019-07-19 19:28'\n",
    "            try:\n",
    "                res_findData=cursor.execute(\"SELECT * FROM bikeData WHERE time LIKE '%%%s%%'\" %timeframe) # find \"key words\" in column time of table bikeData\n",
    "            except:\n",
    "                print('try dump')\n",
    "                conn.close()\n",
    "                time.sleep(10)\n",
    "                dbx.files_download_to_file(save_path,path,None)\n",
    "                print('redownload')\n",
    "                conn = sqlite3.connect(save_path)\n",
    "                cursor = conn.cursor()\n",
    "\n",
    "            if cursor.fetchone() is None:   # No corresponding data to the time, need Optimize\n",
    "                count = 0\n",
    "                print('Bike Data at '+csv_filetime+' does not exist')\n",
    "                pass\n",
    "            else:                   # Have such data\n",
    "                rows = cursor.fetchall()\n",
    "\n",
    "                sum_hP = 0\n",
    "                sum_ThrOut = 0\n",
    "                count = 0\n",
    "\n",
    "                for row in rows:\n",
    "                    sum_hP += row[9]\n",
    "                    sum_ThrOut += row[12]\n",
    "                    count += 1\n",
    "\n",
    "            conn.close()\n",
    "\n",
    "            if count == 0:\n",
    "                pass\n",
    "\n",
    "            else:\n",
    "                ave_hP = sum_hP/count\n",
    "                d5_hP = int(ave_hP/5)\n",
    "                ave_ThrOut = sum_ThrOut/count\n",
    "                d5_ThrOut = int(ave_ThrOut/5)\n",
    "                # export the data processed into file \"export_EBikedata.csv\"\n",
    "\n",
    "                x_t.append(csv_filetime)\n",
    "                y_hP.append(ave_hP)\n",
    "\n",
    "#                 fig = EBikeData_Getting.draw(x_t, y_hP)\n",
    "\n",
    "                with open(\"/Users/tomstanton 1/Documents/College/Stage 5/ME Project/Data/BikeData/EBikedata.csv\", \"a\", newline='\\n') as f:\n",
    "                    headers = ['time', 'average humanPower','average ThrottleOutput']\n",
    "                    writer = csv.writer(f)\n",
    "\n",
    "                    if not os.stat(\"/Users/tomstanton 1/Documents/College/Stage 5/ME Project/Data/BikeData/EBikedata.csv\").st_size:         \n",
    "                        print('Bike Data file created')\n",
    "                        writer.writerow(headers) # file doesn't exist yet, write a header\n",
    "\n",
    "                    # print('have headers')\n",
    "                    writer.writerow([csv_filetime,ave_hP,ave_ThrOut])\n",
    "                    # Remove duplicates\n",
    "                    # pd.read_csv(\"export_EBikedata.csv\").drop_duplicates(subset =\"First Name\",keep = False, inplace = True)\n",
    "                    f.close()\n",
    "                    print('Time: ', csv_filetime ,'. Avg HP: ', ave_hP, '. Ave ThrOut: ', ave_ThrOut, '\\n')\n",
    "                \n",
    "    def StartEBike():\n",
    "        x_t = []\n",
    "        y_hP = []\n",
    "        schedule.every(1).minutes.do(EBikeData_Getting.EBike,x_t,y_hP)\n",
    "\n",
    "        while True:\n",
    "            schedule.run_pending()\n",
    "            \n",
    "    def draw(x_t, y_hP):\n",
    "        plt.clf()\n",
    "        plt.plot(x_t, y_hP, '-r')\n",
    "        plt.tick_params(axis='x', rotation=45)\n",
    "        plt.title('human power verus time')\n",
    "        plt.xlabel('time')\n",
    "        plt.ylabel('human power')\n",
    "        plt.pause(0.01)  # pause a bit so that plots are updated\n",
    "\n",
    "# \n",
    "# \n",
    "# \n",
    "# \n",
    "# \n",
    "\n",
    "class Merging_Data:\n",
    "    \n",
    "    def MergeTable(x_t1,x_t2,x_t3,y_hr,y_eda,y_hP,u,t):\n",
    "        \n",
    "        # concentrate Ebike data and E4 data in one csv file \n",
    "        df3 = pd.read_csv(\"/Users/tomstanton 1/Documents/College/Stage 5/ME Project/Data/BikeData/EBikedata.csv\")\n",
    "        df1 = pd.read_csv(\"/Users/tomstanton 1/Documents/College/Stage 5/ME Project/Data/E4data/bpm_data.csv\")\n",
    "        df2 = pd.read_csv(\"/Users/tomstanton 1/Documents/College/Stage 5/ME Project/Data/E4data/eda_data.csv\")\n",
    "        merged = df1.merge(df2, on=\"time\", how=\"outer\").fillna(\"\")\n",
    "        merged = merged.merge(df3, on=\"time\", how=\"outer\").fillna(\"\")\n",
    "        # merged.replace(\"\", np.nan, inplace=True)            \n",
    "        # merged.dropna(axis=0, how='any',inplace=True)\n",
    "        # merged['time'] =pd.to_datetime(merged['time'], format='%Y-%m-%d-%H-%M')\n",
    "        merged = merged.sort_values(by='time')\n",
    "        # print(merged)\n",
    "        merged.to_csv(\"/Users/tomstanton 1/Documents/College/Stage 5/ME Project/Data/AllData.csv\", index=False)\n",
    "        \n",
    "        dfHR = pd.DataFrame()\n",
    "        dfHR['time']  = x_t1\n",
    "        dfHR['bpm']  = y_hr\n",
    "        dfEDA = pd.DataFrame()\n",
    "        dfEDA['time']  = x_t2\n",
    "        dfEDA['eda']  = y_eda\n",
    "        dfHP = pd.DataFrame()\n",
    "        dfHP['time']  = x_t3\n",
    "        dfHP['hp']  = y_hP\n",
    "        dfU = pd.DataFrame()\n",
    "        dfU['time'] = t\n",
    "        dfU['al'] = u \n",
    "        \n",
    "        dfHR.drop_duplicates(subset =\"time\",keep = 'first', inplace = True) \n",
    "        dfEDA.drop_duplicates(subset =\"time\",keep = 'first', inplace = True) \n",
    "        dfHP.drop_duplicates(subset =\"time\",keep = 'first', inplace = True) \n",
    "        dfU.drop_duplicates(subset =\"time\",keep = 'first', inplace = True) \n",
    "        x_t1 = dfHR.time\n",
    "        y_hr = dfHR.bpm\n",
    "        x_t2 = dfEDA.time\n",
    "        y_eda = dfEDA.eda\n",
    "        x_t3 = dfHP.time\n",
    "        y_hP = dfHP.hp\n",
    "        t = dfU.time\n",
    "        u = dfU.al\n",
    "        \n",
    "        currCycle = dfHR.merge(dfEDA, on=\"time\", how=\"outer\").fillna(\"\")\n",
    "        currCycle = currCycle.merge(dfHP, on=\"time\", how=\"outer\").fillna(\"\")\n",
    "        currCycle = currCycle.merge(dfU, on=\"time\", how=\"outer\").fillna(\"\")\n",
    "        currCycle = currCycle.sort_values(by='time')\n",
    "        currCycle.to_csv(\"/Users/tomstanton 1/Documents/College/Stage 5/ME Project/Data/CurrentCycleData.csv\", index=False)\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "class SysID_MPC:\n",
    "    \n",
    "    def ModelAndControl(u,t):\n",
    "        \n",
    "        # System Identification module\n",
    "        # Ignore warning prints\n",
    "        warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "        # Current Cycle Data\n",
    "        currCycle = pd.read_csv(\"/Users/tomstanton 1/Documents/College/Stage 5/ME Project/Data/CurrentCycleData.csv\")\n",
    "        currCycle=currCycle.dropna(subset = ['bpm','eda','hp'])\n",
    "        currCycleReadings = len(currCycle.time)\n",
    "        x1h = currCycle.bpm\n",
    "        x2h = currCycle.eda\n",
    "        x3h = currCycle.hp\n",
    "        uh = currCycle.al\n",
    "\n",
    "        # Training Data\n",
    "        trainData = pd.read_csv(\"/Users/tomstanton 1/Documents/College/Stage 5/ME Project/Data/TrainingData.csv\")\n",
    "        trainReadings = len(trainData.time)\n",
    "        x1t = trainData.bpm\n",
    "        x2t = trainData.eda\n",
    "        x3t = trainData.hp\n",
    "        ut = trainData.al\n",
    "\n",
    "\n",
    "        # Initialize Model\n",
    "        m = GEKKO()\n",
    "\n",
    "        # Initialize Variables\n",
    "        a12,a13,a21,a23,a31,a32,b1,b2,b3  = [m.Var() for i in range(9)]\n",
    "        e = m.Array(m.Var,((currCycleReadings)*3)) # error [recorded]\n",
    "        et = m.Array(m.Var,((trainReadings)*3)) # error [training]\n",
    "\n",
    "\n",
    "        # Equations\n",
    "        for i in range(0,currCycleReadings-1):\n",
    "            # Recorded Data Constraints\n",
    "            m.Equation(x1h[i+1]-x1h[i] == a12*x2h[i] + a13*x3h[i] + b1*uh[i]+e[i*3+1])\n",
    "            m.Equation(x2h[i+1]-x2h[i] == a21*x1h[i] + a23*x3h[i] + b2*uh[i]+e[i*3+2])\n",
    "            m.Equation(x3h[i+1]-x3h[i] == a31*x1h[i] + a32*x2h[i] + b3*uh[i]+e[i*3+3])\n",
    "\n",
    "            # Training Data Constraints\n",
    "            m.Equation(x1t[i+1]-x1t[i] == a12*x2t[i] + a13*x3t[i] + b1*ut[i]+et[i*3+1])\n",
    "            m.Equation(x2t[i+1]-x2t[i] == a21*x1t[i] + a23*x3t[i] + b2*ut[i]+et[i*3+2])\n",
    "            m.Equation(x3t[i+1]-x3t[i] == a31*x1t[i] + a32*x2t[i] + b3*ut[i]+et[i*3+3])\n",
    "\n",
    "\n",
    "        # Objective\n",
    "        m.Obj(sum(numpy.square(e))+sum(numpy.square(e)))\n",
    "        m.options.IMODE = 3 # MPU\n",
    "        m.options.MAX_ITER = 10000\n",
    "        m.solve(disp=False)\n",
    "\n",
    "\n",
    "        # MPC Module\n",
    "        \n",
    "        # Initialize X component values at time k\n",
    "        x1k = currCycle.bpm[currCycleReadings-1]\n",
    "        x2k = currCycle.eda[currCycleReadings-1]\n",
    "        x3k = currCycle.hp[currCycleReadings-1]\n",
    "        \n",
    "        # Get previous prediction table if one exists\n",
    "        if currCycleReadings>1:\n",
    "            try:\n",
    "                str_filetime = (datetime.datetime.now() - datetime.timedelta(minutes = 2)).strftime('%Y-%m-%d-%H-%M')\n",
    "                filepath = '/Users/tomstanton 1/Documents/College/Stage 5/ME Project/Data/MPC_Predictions/'+str_filetime+'.csv'\n",
    "                dfPredict = pd.read_csv(filepath)\n",
    "            except:\n",
    "                print(\"Error finding previous MPC output data\")\n",
    "            else:\n",
    "                print(\"MPC predictions found\")\n",
    "\n",
    "        \n",
    "        # Fill in missing data in current frame using predicted mpc value in last frame or initial set values    \n",
    "        flag=0\n",
    "        \n",
    "        if numpy.isnan(x1k):\n",
    "            flag=1\n",
    "            if currCycleReadings<=1:\n",
    "                x1k = 70\n",
    "            else:\n",
    "                x1k = dfPredict.bpm[1]\n",
    "\n",
    "        if numpy.isnan(x2k):\n",
    "            flag=1\n",
    "            if currCycleReadings<=1:\n",
    "                x2k = 0.05\n",
    "            else:\n",
    "                x2k = dfPredict.eda[2]\n",
    "\n",
    "        if numpy.isnan(x3k):\n",
    "            flag=1\n",
    "            if currCycleReadings<=1:\n",
    "                x3k = 0\n",
    "            else:\n",
    "                x3k = dfPredict.hp[1]\n",
    "                \n",
    "        if flag==1:\n",
    "#             ccEdit= pd.read_csv(\"/Users/tomstanton 1/Documents/College/Stage 5/ME Project/Data/CurrentCycleData.csv\")\n",
    "#             ccEdit.bpm[currCycleReadings-1]=x1k\n",
    "#             ccEdit.eda[currCycleReadings-1]=x2k\n",
    "#             ccEdit.hp[currCycleReadings-1]=x3k\n",
    "#             ccEdit.to_csv(\"/Users/tomstanton 1/Documents/College/Stage 5/ME Project/Data/CurrentCycleData.csv\", index=False)\n",
    "            y_hr[len(y_hr)]=x1k\n",
    "            y_eda[len(y_eda)]=x2k\n",
    "            y_hP[len(hP)]=x3k\n",
    "\n",
    "\n",
    "        # Output matrices A and b from system identification model\n",
    "        a11 = 1\n",
    "        a12 =  float(str(a12.value)[1:-1])\n",
    "        a13 =  float(str(a13.value)[1:-1])\n",
    "        a21 =  float(str(a21.value)[1:-1])\n",
    "        a22 = 1\n",
    "        a23 =  float(str(a23.value)[1:-1])\n",
    "        a31 =  float(str(a31.value)[1:-1])\n",
    "        a32 =  float(str(a32.value)[1:-1])\n",
    "        a33 = 1\n",
    "        b1 =  float(str(b1.value)[1:-1])\n",
    "        b2 =  float(str(b2.value)[1:-1])\n",
    "        b3 =  float(str(b3.value)[1:-1])\n",
    "\n",
    "\n",
    "        # Initialize Model\n",
    "        n = GEKKO()\n",
    "\n",
    "        # Constants\n",
    "        bpmMax = 160\n",
    "\n",
    "        # Initialize Variables\n",
    "        x1k1 = n.Var(lb = 0, ub = 200)\n",
    "        x2k1 = n.Var(lb = 0, ub = 50)\n",
    "        x3k1 = n.Var(lb = 0, ub = 1000) \n",
    "        uk = n.Var(lb = 0, ub = 1) \n",
    "        x1k2 = n.Var(lb = 0, ub = 200)\n",
    "        x2k2 = n.Var(lb = 0, ub = 50)\n",
    "        x3k2 = n.Var(lb = 0, ub = 1000) \n",
    "        uk1 = n.Var(lb = 0, ub = 1) \n",
    "        x1k3 = n.Var(lb = 0, ub = 200)\n",
    "        x2k3 = n.Var(lb = 0, ub = 50)\n",
    "        x3k3 = n.Var(lb = 0, ub = 1000) \n",
    "        uk2 = n.Var(lb = 0, ub = 1) \n",
    "#         x1k4 = n.Var(lb = 0, ub = 200)\n",
    "#         x2k4 = n.Var(lb = 0, ub = 50)\n",
    "#         x3k4 = n.Var(lb = 0, ub = 1000) \n",
    "#         uk3 = n.Var(lb = 0, ub = 1) \n",
    "#         x1k5 = n.Var(lb = 0, ub = 200)\n",
    "#         x2k5 = n.Var(lb = 0, ub = 50)\n",
    "#         x3k5 = n.Var(lb = 0, ub = 1000) \n",
    "#         uk4 = n.Var(lb = 0, ub = 1) \n",
    "\n",
    "        # Equations\n",
    "        n.Equation(x1k1 == a11*x1k + a12*x2k + a13*x3k + b1*uk)\n",
    "        n.Equation(x2k1 == a21*x1k + a22*x2k + a23*x3k + b2*uk)\n",
    "        n.Equation(x3k1 == a31*x1k + a32*x2k + a33*x3k + b3*uk)\n",
    "        n.Equation(x1k1 <= bpmMax)\n",
    "        n.Equation(x1k1 >= x1k)\n",
    "        n.Equation(x1k2 == a11*x1k1 + a12*x2k1 + a13*x3k1 + b1*uk1)\n",
    "        n.Equation(x2k2 == a21*x1k1 + a22*x2k1 + a23*x3k1 + b2*uk1)\n",
    "        n.Equation(x3k2 == a31*x1k1 + a32*x2k1 + a33*x3k1 + b3*uk1)\n",
    "        n.Equation(x1k2 <= bpmMax)\n",
    "        n.Equation(x1k2 >= x1k1)\n",
    "        n.Equation(x1k3 == a11*x1k2 + a12*x2k2 + a13*x3k2 + b1*uk2)\n",
    "        n.Equation(x2k3 == a21*x1k2 + a22*x2k2 + a23*x3k2 + b2*uk2)\n",
    "        n.Equation(x3k3 == a31*x1k2 + a32*x2k2 + a33*x3k2 + b3*uk2)\n",
    "        n.Equation(x1k3 <= bpmMax)\n",
    "        n.Equation(x1k3 >= x1k2)\n",
    "#         n.Equation(x1k4 == a11*x1k3 + a12*x2k3 + a13*x3k3 + b1*uk3)\n",
    "#         n.Equation(x2k4 == a21*x1k3 + a22*x2k3 + a23*x3k3 + b2*uk3)\n",
    "#         n.Equation(x3k4 == a31*x1k3 + a32*x2k3 + a33*x3k3 + b3*uk3)\n",
    "#         n.Equation(x1k4 <= bpmMax)\n",
    "#         n.Equation(x1k4 >= x1k3)\n",
    "#         n.Equation(x1k5 == a11*x1k4 + a12*x2k4 + a13*x3k4 + b1*uk4)\n",
    "#         n.Equation(x2k5 == a21*x1k4 + a22*x2k4 + a23*x3k4 + b2*uk4)\n",
    "#         n.Equation(x3k5 == a31*x1k4 + a32*x2k4 + a33*x3k4 + b3*uk4)\n",
    "#         n.Equation(x1k5 <= bpmMax)\n",
    "#         n.Equation(x1k5 >= x1k4)\n",
    "\n",
    "        # Objective\n",
    "#         n.Obj(uk+uk1+uk2+uk3+uk4)\n",
    "        n.Obj(uk+uk1+uk2)\n",
    "        n.options.IMODE = 3\n",
    "        n.options.MAX_ITER = 10000\n",
    "        n.solve(disp=False)\n",
    "\n",
    "        x1k1 = float(str(x1k1.value)[1:-1])\n",
    "        x1k2 = float(str(x1k2.value)[1:-1])\n",
    "        x1k3 = float(str(x1k3.value)[1:-1])\n",
    "#         x1k4 = float(str(x1k4.value)[1:-1])\n",
    "#         x1k5 = float(str(x1k5.value)[1:-1])\n",
    "        x2k1 = float(str(x2k1.value)[1:-1])\n",
    "        x2k2 = float(str(x2k2.value)[1:-1])\n",
    "        x2k3 = float(str(x2k3.value)[1:-1])\n",
    "#         x2k4 = float(str(x2k4.value)[1:-1])\n",
    "#         x2k5 = float(str(x2k5.value)[1:-1])\n",
    "        x3k1 = float(str(x3k1.value)[1:-1])\n",
    "        x3k2 = float(str(x3k2.value)[1:-1])\n",
    "        x3k3 = float(str(x3k3.value)[1:-1])\n",
    "#         x3k4 = float(str(x3k4.value)[1:-1])\n",
    "#         x3k5 = float(str(x3k5.value)[1:-1])\n",
    "        uk = round(float(str(uk.value)[1:-1]),2)\n",
    "        uk1 = round(float(str(uk1.value)[1:-1]),2)\n",
    "        uk2 = round(float(str(uk2.value)[1:-1]),2)\n",
    "#         uk3 = round(float(str(uk3.value)[1:-1]),2)\n",
    "#         uk4 = round(float(str(uk4.value)[1:-1]),2)\n",
    "\n",
    "        # Output\n",
    "        prediction = [[0,x1k,x2k,x3k,uk],[1,x1k1,x2k1,x3k1,uk1],[2,x1k2,x2k2,x3k2,uk2],[3,x1k3,x2k3,x3k3]]\n",
    "#         prediction = [[0,x1k,x2k,x3k,uk],[1,x1k1,x2k1,x3k1,uk1],[2,x1k2,x2k2,x3k2,uk2],[3,x1k3,x2k3,x3k3,uk3],[4,x1k4,x2k4,x3k4,uk4],[5,x1k5,x2k5,x3k5]]  \n",
    "        # Create the pandas DataFrame \n",
    "        dfOut = pd.DataFrame(prediction, columns = ['k', 'bpm','eda','hp','al']) \n",
    "        filename = currCycle.time[currCycleReadings-1] \n",
    "        dfOut.to_csv(\"/Users/tomstanton 1/Documents/College/Stage 5/ME Project/Data/MPC_Predictions/\"+filename+'.csv', index=False)\n",
    "#         ccToEdit= pd.read_csv(\"/Users/tomstanton 1/Documents/College/Stage 5/ME Project/Data/CurrentCycleData.csv\")\n",
    "#         ccToEdit.al[currCycleReadings-1]=uk\n",
    "#         ukCheck = uk+4\n",
    "#         ccToEdit.to_csv(\"/Users/tomstanton 1/Documents/College/Stage 5/ME Project/Data/CurrentCycleData.csv\", index=False)\n",
    "        # OUTPUT U TO BIKE\n",
    "        print('U = ',uk)\n",
    "        u.append(uk)\n",
    "        t.append(filename)\n",
    "        \n",
    "# \n",
    "# \n",
    "#\n",
    "class UploadAL:\n",
    "    def UploadToDropbox(u):\n",
    "        dbx = dropbox.Dropbox('ZUWX93O8oqAAAAAAAAAAxEHAYxN4vo5YaNUpj9rUXX6A0PTm25VJRNpC-gVEn7QO')\n",
    "        pc_path = '/Users/tomstanton 1/Documents/College/Stage 5/ME Project/Data/Bikedata/Al.csv'  \n",
    "        db_path = '/AL.csv'\n",
    "        dfAl = pd.DataFrame()\n",
    "        dfAl['AL']  = u\n",
    "        dfAl.to_csv(pc_path, index=False)\n",
    "        f = open(pc_path,\"rb\")\n",
    "        overwrite = dropbox.files.WriteMode('overwrite', None)\n",
    "        dbx.files_upload(f.read(),db_path,mode=overwrite,autorename=False)\n",
    "        f.close()\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "class CombineAll:\n",
    "    def DoAllEveryMin(x_t1,y_hr,x_t2,y_eda,x_t3,y_hP,u,t):\n",
    "        filetime = datetime.datetime.now() - datetime.timedelta(minutes = 1)\n",
    "        currTime = filetime.strftime('%Y-%m-%d-%H-%M')\n",
    "        currTimeFrame=filetime.strftime('%Y-%m-%d %H:%M')\n",
    "        \n",
    "        HR_Getting.E4(x_t1,y_hr,currTime)\n",
    "        SC_Getting.E4(x_t2,y_eda,currTime)\n",
    "        time.sleep(10)\n",
    "        EBikeData_Getting.EBike(x_t3,y_hP,currTime,currTimeFrame)\n",
    "        Merging_Data.MergeTable(x_t1,x_t2,x_t3,y_hr,y_eda,y_hP,u,t)\n",
    "        time.sleep(20)\n",
    "        SysID_MPC.ModelAndControl(u,t)\n",
    "        \n",
    "    def GetTime(currTime, currTimeFrame):\n",
    "        filetime = datetime.datetime.now() - datetime.timedelta(minutes = 1)\n",
    "        currTime = filetime.strftime('%Y-%m-%d-%H-%M')\n",
    "        currTimeFrame=filetime.strftime('%Y-%m-%d %H:%M')\n",
    "        \n",
    "        \n",
    "# \n",
    "# \n",
    "# \n",
    "# \n",
    "# \n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    schedule.clear()\n",
    "    x_t1 = []\n",
    "    y_hr = []\n",
    "    x_t2 = []\n",
    "    y_eda = []\n",
    "    x_t3 = []\n",
    "    y_hP = []\n",
    "    u = []\n",
    "    t = []\n",
    "    currTime = \"\"\n",
    "    currTimeFrame = \"\"\n",
    "    \n",
    "    \n",
    "#     schedule.every(1).minutes.do(CombineAll.DoAllEveryMin,x_t1,y_hr,x_t2,y_eda,x_t3,y_hP,u,t)\n",
    "#     schedule.every(1).minutes.do(CombineAll.GetTime,currTime,currTimeFrame)\n",
    "    schedule.every(1).minutes.do(HR_Getting.E4, x_t1, y_hr)\n",
    "    schedule.every(1).minutes.do(SC_Getting.E4, x_t2, y_eda)\n",
    "    schedule.every(1).minutes.do(EBikeData_Getting.EBike,x_t3,y_hP)\n",
    "    schedule.every(1).minutes.do(Merging_Data.MergeTable,x_t1,x_t2,x_t3,y_hr,y_eda,y_hP,u,t)\n",
    "    schedule.every(1).minutes.do(SysID_MPC.ModelAndControl,u,t)\n",
    "    schedule.every(1).minutes.do(UploadAL.UploadToDropboxs,u)\n",
    "    \n",
    "    while True:\n",
    "        schedule.run_pending()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#currCycle.drop_duplicates(subset =\"time\",keep = 'first', inplace = True) \n",
    "u = []\n",
    "u.append(1)\n",
    "u.append(2)\n",
    "u.append(3)\n",
    "u.append(4)\n",
    "\n",
    "import dropbox\n",
    "import pandas as pd\n",
    "\n",
    "dbx = dropbox.Dropbox('ZUWX93O8oqAAAAAAAAAAxEHAYxN4vo5YaNUpj9rUXX6A0PTm25VJRNpC-gVEn7QO')\n",
    "pc_path = '/Users/tomstanton 1/Documents/College/Stage 5/ME Project/Data/Bikedata/Al.csv'  \n",
    "db_path = '/AL.csv'\n",
    "dfAl = pd.DataFrame()\n",
    "dfAl['AL']  = u\n",
    "dfAl.to_csv(pc_path, index=False)\n",
    "f= open(pc_path,\"rb\")\n",
    "overwrite = dropbox.files.WriteMode('overwrite', None)\n",
    "dbx.files_upload(f.read(),db_path,mode=overwrite,autorename=False)\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
